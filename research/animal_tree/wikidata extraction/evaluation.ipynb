{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbceda47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation...\n",
      "================================================================================\n",
      "\n",
      "Testing: domain_kingdom\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Parent: Eukarya -> kingdom\n",
      "Expected: 4 items\n",
      "Predicted: 4 items\n",
      "TP: 4, FP: 0, FN: 0\n",
      "Sample predictions: ['Fungi', 'Plantae', 'Animalia']\n",
      "\n",
      "Parent: Bacteria -> kingdom\n",
      "Expected: 1 items\n",
      "Predicted: 1 items\n",
      "TP: 1, FP: 0, FN: 0\n",
      "Sample predictions: ['Bacteria']\n",
      "\n",
      "Parent: Archaea -> kingdom\n",
      "Expected: 1 items\n",
      "Predicted: 1 items\n",
      "TP: 1, FP: 0, FN: 0\n",
      "Sample predictions: ['Archaea']\n",
      "\n",
      "Testing: kingdom_phylum\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Parent: Animalia -> phylum\n",
      "Expected: 9 items\n",
      "Predicted: 10 items\n",
      "TP: 1, FP: 9, FN: 8\n",
      "Sample predictions: ['Monoblastozoa', 'Porifera', 'Vendozoa']\n",
      "\n",
      "Parent: Plantae -> phylum\n",
      "Expected: 3 items\n",
      "Predicted: 5 items\n",
      "TP: 0, FP: 5, FN: 3\n",
      "Sample predictions: ['sporae dispersae', 'Euthallophyta', 'Hepatophyta']\n",
      "\n",
      "Testing: phylum_class\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Parent: Chordata -> class\n",
      "Expected: 6 items\n",
      "Predicted: 0 items\n",
      "TP: 0, FP: 0, FN: 6\n",
      "\n",
      "Parent: Arthropoda -> class\n",
      "Expected: 4 items\n",
      "Predicted: 7 items\n",
      "TP: 0, FP: 7, FN: 4\n",
      "Sample predictions: ['Marrellomorpha', 'Monomalata', 'Scorpionida']\n",
      "\n",
      "Testing: class_order\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Parent: Mammalia -> order\n",
      "Expected: 8 items\n",
      "Predicted: 10 items\n",
      "TP: 2, FP: 8, FN: 6\n",
      "Sample predictions: ['Eutriconodonta', 'Pilosa', 'Chiroptera']\n",
      "\n",
      "Parent: Aves -> order\n",
      "Expected: 5 items\n",
      "Predicted: 10 items\n",
      "TP: 0, FP: 10, FN: 5\n",
      "Sample predictions: ['Galbuliformes', 'Upupiformes', 'Trochiliformes']\n",
      "\n",
      "Parent: Insecta -> order\n",
      "Expected: 5 items\n",
      "Predicted: 5 items\n",
      "TP: 0, FP: 5, FN: 5\n",
      "Sample predictions: ['Mischopterida', 'Zygentoma', 'Glosselytrodea']\n",
      "\n",
      "Testing: order_family\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Parent: Primates -> family\n",
      "Expected: 5 items\n",
      "Predicted: 8 items\n",
      "TP: 0, FP: 8, FN: 5\n",
      "Sample predictions: ['Indriidae', 'Microsyopidae', 'Pithecidae']\n",
      "\n",
      "Parent: Carnivora -> family\n",
      "Expected: 5 items\n",
      "Predicted: 3 items\n",
      "TP: 0, FP: 3, FN: 5\n",
      "Sample predictions: ['Ailuridae', 'Adapisoriculidae', 'Ailuropodidae']\n",
      "\n",
      "Parent: Rodentia -> family\n",
      "Expected: 4 items\n",
      "Predicted: 10 items\n",
      "TP: 0, FP: 10, FN: 4\n",
      "Sample predictions: ['Ivanantoniidae', 'Cricetopidae', 'Eurymylidae']\n",
      "\n",
      "Testing: family_genus\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Parent: Hominidae -> genus\n",
      "Expected: 4 items\n",
      "Predicted: 10 items\n",
      "TP: 2, FP: 8, FN: 2\n",
      "Sample predictions: ['Equatorius', 'Langsonia', 'Pan']\n",
      "\n",
      "Parent: Felidae -> genus\n",
      "Expected: 5 items\n",
      "Predicted: 10 items\n",
      "TP: 0, FP: 10, FN: 5\n",
      "Sample predictions: ['Oncifelis', 'Miopanthera', 'Drepanodon']\n",
      "\n",
      "Parent: Canidae -> genus\n",
      "Expected: 3 items\n",
      "Predicted: 10 items\n",
      "TP: 1, FP: 9, FN: 2\n",
      "Sample predictions: ['Otarocyon', 'Archaeocyon', 'Eucyon']\n",
      "\n",
      "Testing: genus_species\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Parent: Homo -> species\n",
      "Expected: 1 items\n",
      "Predicted: 10 items\n",
      "TP: 1, FP: 9, FN: 0\n",
      "Sample predictions: ['Neanderthal', 'Homo njarasensis', 'Homo sapiens']\n",
      "\n",
      "Parent: Canis -> species\n",
      "Expected: 3 items\n",
      "Predicted: 10 items\n",
      "TP: 1, FP: 9, FN: 2\n",
      "Sample predictions: ['Canis nehringi', 'Canis simensis', 'Canis apolloniensis']\n",
      "\n",
      "Parent: Panthera -> species\n",
      "Expected: 4 items\n",
      "Predicted: 10 items\n",
      "TP: 0, FP: 10, FN: 4\n",
      "Sample predictions: ['leopard', 'European jaguar', 'Panthera zdanskyi']\n",
      "\n",
      "================================================================================\n",
      "VALIDATION METRICS\n",
      "================================================================================\n",
      "\n",
      "Total Queries: 19\n",
      "Total True Positives: 14\n",
      "Total False Positives: 120\n",
      "Total False Negatives: 66\n",
      "\n",
      "Metric               Value     \n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy             0.1045\n",
      "\n",
      "Macro Metrics:      \n",
      "  Precision          0.2000\n",
      "  Recall             0.2909\n",
      "  F1-Score           0.2159\n",
      "\n",
      "Micro Metrics:      \n",
      "  Precision          0.1045\n",
      "  Recall             0.1750\n",
      "  F1-Score           0.1308\n",
      "================================================================================\n",
      "\n",
      "Results saved to validation_results.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Validation suite for TaxonomyExpander model with comprehensive test dataset\n",
    "and metric calculations.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Set\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Comprehensive validation dataset with known taxonomic relationships\n",
    "VALIDATION_DATASET = {\n",
    "    # Domain -> Kingdom\n",
    "    \"domain_kingdom\": [\n",
    "        {\"parent\": \"Eukarya\", \"rank\": \"kingdom\", \"expected\": {\"Animalia\", \"Plantae\", \"Fungi\", \"Protista\"}},\n",
    "        {\"parent\": \"Bacteria\", \"rank\": \"kingdom\", \"expected\": {\"Bacteria\"}},\n",
    "        {\"parent\": \"Archaea\", \"rank\": \"kingdom\", \"expected\": {\"Archaea\"}},\n",
    "    ],\n",
    "    \n",
    "    # Kingdom -> Phylum (Animalia)\n",
    "    \"kingdom_phylum\": [\n",
    "        {\"parent\": \"Animalia\", \"rank\": \"phylum\", \"expected\": {\n",
    "            \"Chordata\", \"Arthropoda\", \"Mollusca\", \"Annelida\", \"Echinodermata\",\n",
    "            \"Cnidaria\", \"Platyhelminthes\", \"Nematoda\", \"Porifera\"\n",
    "        }},\n",
    "        {\"parent\": \"Plantae\", \"rank\": \"phylum\", \"expected\": {\n",
    "            \"Tracheophyta\", \"Bryophyta\", \"Marchantiophyta\"\n",
    "        }},\n",
    "    ],\n",
    "    \n",
    "    # Phylum -> Class\n",
    "    \"phylum_class\": [\n",
    "        {\"parent\": \"Chordata\", \"rank\": \"class\", \"expected\": {\n",
    "            \"Mammalia\", \"Aves\", \"Reptilia\", \"Amphibia\", \"Actinopterygii\", \"Chondrichthyes\"\n",
    "        }},\n",
    "        {\"parent\": \"Arthropoda\", \"rank\": \"class\", \"expected\": {\n",
    "            \"Insecta\", \"Arachnida\", \"Crustacea\", \"Myriapoda\"\n",
    "        }},\n",
    "    ],\n",
    "    \n",
    "    # Class -> Order\n",
    "    \"class_order\": [\n",
    "        {\"parent\": \"Mammalia\", \"rank\": \"order\", \"expected\": {\n",
    "            \"Primates\", \"Carnivora\", \"Rodentia\", \"Chiroptera\", \"Cetacea\",\n",
    "            \"Artiodactyla\", \"Perissodactyla\", \"Proboscidea\"\n",
    "        }},\n",
    "        {\"parent\": \"Aves\", \"rank\": \"order\", \"expected\": {\n",
    "            \"Passeriformes\", \"Falconiformes\", \"Strigiformes\", \"Psittaciformes\", \"Columbiformes\"\n",
    "        }},\n",
    "        {\"parent\": \"Insecta\", \"rank\": \"order\", \"expected\": {\n",
    "            \"Coleoptera\", \"Lepidoptera\", \"Hymenoptera\", \"Diptera\", \"Hemiptera\"\n",
    "        }},\n",
    "    ],\n",
    "    \n",
    "    # Order -> Family\n",
    "    \"order_family\": [\n",
    "        {\"parent\": \"Primates\", \"rank\": \"family\", \"expected\": {\n",
    "            \"Hominidae\", \"Cercopithecidae\", \"Hylobatidae\", \"Lemuridae\", \"Callitrichidae\"\n",
    "        }},\n",
    "        {\"parent\": \"Carnivora\", \"rank\": \"family\", \"expected\": {\n",
    "            \"Felidae\", \"Canidae\", \"Ursidae\", \"Mustelidae\", \"Phocidae\"\n",
    "        }},\n",
    "        {\"parent\": \"Rodentia\", \"rank\": \"family\", \"expected\": {\n",
    "            \"Muridae\", \"Sciuridae\", \"Cricetidae\", \"Castoridae\"\n",
    "        }},\n",
    "    ],\n",
    "    \n",
    "    # Family -> Genus\n",
    "    \"family_genus\": [\n",
    "        {\"parent\": \"Hominidae\", \"rank\": \"genus\", \"expected\": {\n",
    "            \"Homo\", \"Pan\", \"Gorilla\", \"Pongo\"\n",
    "        }},\n",
    "        {\"parent\": \"Felidae\", \"rank\": \"genus\", \"expected\": {\n",
    "            \"Panthera\", \"Felis\", \"Lynx\", \"Puma\", \"Acinonyx\"\n",
    "        }},\n",
    "        {\"parent\": \"Canidae\", \"rank\": \"genus\", \"expected\": {\n",
    "            \"Canis\", \"Vulpes\", \"Lycaon\"\n",
    "        }},\n",
    "    ],\n",
    "    \n",
    "    # Genus -> Species\n",
    "    \"genus_species\": [\n",
    "        {\"parent\": \"Homo\", \"rank\": \"species\", \"expected\": {\n",
    "            \"Homo sapiens\"\n",
    "        }},\n",
    "        {\"parent\": \"Canis\", \"rank\": \"species\", \"expected\": {\n",
    "            \"Canis lupus\", \"Canis familiaris\", \"Canis latrans\"\n",
    "        }},\n",
    "        {\"parent\": \"Panthera\", \"rank\": \"species\", \"expected\": {\n",
    "            \"Panthera leo\", \"Panthera tigris\", \"Panthera pardus\", \"Panthera onca\"\n",
    "        }},\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "class TaxonomyValidator:\n",
    "    \"\"\"Validates taxonomy model predictions against ground truth.\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.results = []\n",
    "        \n",
    "    def validate_single(self, parent: str, rank: str, expected: Set[str]) -> Dict:\n",
    "        \"\"\"Validate a single query and return metrics.\"\"\"\n",
    "        # Get the appropriate method based on rank\n",
    "        method_name = f\"get_{rank}\"\n",
    "        if not hasattr(self.model, method_name):\n",
    "            return {\n",
    "                \"parent\": parent,\n",
    "                \"rank\": rank,\n",
    "                \"predicted\": set(),\n",
    "                \"expected\": expected,\n",
    "                \"tp\": 0, \"fp\": 0, \"fn\": len(expected), \"tn\": 0\n",
    "            }\n",
    "        \n",
    "        method = getattr(self.model, method_name)\n",
    "        \n",
    "        # Execute query\n",
    "        try:\n",
    "            if rank == \"kingdom\":\n",
    "                predicted = set(method(parent))\n",
    "            else:\n",
    "                predicted = set(method(parent))\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying {parent} -> {rank}: {e}\")\n",
    "            predicted = set()\n",
    "        \n",
    "        # Calculate confusion matrix elements\n",
    "        tp = len(predicted & expected)  # True Positives\n",
    "        fp = len(predicted - expected)  # False Positives\n",
    "        fn = len(expected - predicted)  # False Negatives\n",
    "        \n",
    "        return {\n",
    "            \"parent\": parent,\n",
    "            \"rank\": rank,\n",
    "            \"predicted\": predicted,\n",
    "            \"expected\": expected,\n",
    "            \"tp\": tp,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn,\n",
    "            \"tn\": 0  # TN not well-defined in this context\n",
    "        }\n",
    "    \n",
    "    def run_validation(self) -> List[Dict]:\n",
    "        \"\"\"Run full validation on the dataset.\"\"\"\n",
    "        print(\"Starting validation...\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for category, test_cases in VALIDATION_DATASET.items():\n",
    "            print(f\"\\nTesting: {category}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            for test_case in test_cases:\n",
    "                result = self.validate_single(\n",
    "                    test_case[\"parent\"],\n",
    "                    test_case[\"rank\"],\n",
    "                    test_case[\"expected\"]\n",
    "                )\n",
    "                self.results.append(result)\n",
    "                \n",
    "                # Print result\n",
    "                print(f\"\\nParent: {result['parent']} -> {result['rank']}\")\n",
    "                print(f\"Expected: {len(result['expected'])} items\")\n",
    "                print(f\"Predicted: {len(result['predicted'])} items\")\n",
    "                print(f\"TP: {result['tp']}, FP: {result['fp']}, FN: {result['fn']}\")\n",
    "                \n",
    "                if result['predicted']:\n",
    "                    print(f\"Sample predictions: {list(result['predicted'])[:3]}\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def calculate_metrics(self) -> Dict:\n",
    "        \"\"\"Calculate all evaluation metrics.\"\"\"\n",
    "        if not self.results:\n",
    "            return {}\n",
    "        \n",
    "        # Aggregate counts\n",
    "        total_tp = sum(r['tp'] for r in self.results)\n",
    "        total_fp = sum(r['fp'] for r in self.results)\n",
    "        total_fn = sum(r['fn'] for r in self.results)\n",
    "        \n",
    "        # Micro metrics (aggregate all predictions)\n",
    "        precision_micro = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "        recall_micro = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "        f1_micro = (2 * precision_micro * recall_micro / (precision_micro + recall_micro) \n",
    "                   if (precision_micro + recall_micro) > 0 else 0)\n",
    "        \n",
    "        # Macro metrics (average per query)\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1s = []\n",
    "        \n",
    "        for r in self.results:\n",
    "            # Precision for this query\n",
    "            p = r['tp'] / (r['tp'] + r['fp']) if (r['tp'] + r['fp']) > 0 else 0\n",
    "            precisions.append(p)\n",
    "            \n",
    "            # Recall for this query\n",
    "            rec = r['tp'] / (r['tp'] + r['fn']) if (r['tp'] + r['fn']) > 0 else 0\n",
    "            recalls.append(rec)\n",
    "            \n",
    "            # F1 for this query\n",
    "            f1 = 2 * p * rec / (p + rec) if (p + rec) > 0 else 0\n",
    "            f1s.append(f1)\n",
    "        \n",
    "        precision_macro = np.mean(precisions)\n",
    "        recall_macro = np.mean(recalls)\n",
    "        f1_macro = np.mean(f1s)\n",
    "        \n",
    "        # Accuracy (correct predictions / total predictions made)\n",
    "        total_predictions = sum(len(r['predicted']) for r in self.results)\n",
    "        total_expected = sum(len(r['expected']) for r in self.results)\n",
    "        accuracy = total_tp / max(total_predictions, total_expected) if max(total_predictions, total_expected) > 0 else 0\n",
    "        \n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision_macro\": precision_macro,\n",
    "            \"recall_macro\": recall_macro,\n",
    "            \"f1_macro\": f1_macro,\n",
    "            \"precision_micro\": precision_micro,\n",
    "            \"recall_micro\": recall_micro,\n",
    "            \"f1_micro\": f1_micro,\n",
    "            \"total_queries\": len(self.results),\n",
    "            \"total_tp\": total_tp,\n",
    "            \"total_fp\": total_fp,\n",
    "            \"total_fn\": total_fn,\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def print_metrics(self):\n",
    "        \"\"\"Print formatted metrics report.\"\"\"\n",
    "        metrics = self.calculate_metrics()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"VALIDATION METRICS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\nTotal Queries: {metrics['total_queries']}\")\n",
    "        print(f\"Total True Positives: {metrics['total_tp']}\")\n",
    "        print(f\"Total False Positives: {metrics['total_fp']}\")\n",
    "        print(f\"Total False Negatives: {metrics['total_fn']}\")\n",
    "        print(f\"\\n{'Metric':<20} {'Value':<10}\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Accuracy':<20} {metrics['accuracy']:.4f}\")\n",
    "        print(f\"\\n{'Macro Metrics:':<20}\")\n",
    "        print(f\"{'  Precision':<20} {metrics['precision_macro']:.4f}\")\n",
    "        print(f\"{'  Recall':<20} {metrics['recall_macro']:.4f}\")\n",
    "        print(f\"{'  F1-Score':<20} {metrics['f1_macro']:.4f}\")\n",
    "        print(f\"\\n{'Micro Metrics:':<20}\")\n",
    "        print(f\"{'  Precision':<20} {metrics['precision_micro']:.4f}\")\n",
    "        print(f\"{'  Recall':<20} {metrics['recall_micro']:.4f}\")\n",
    "        print(f\"{'  F1-Score':<20} {metrics['f1_micro']:.4f}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Import your model\n",
    "    from taxonomy_expander import TaxonomyExpander\n",
    "    \n",
    "    # Initialize model and validator\n",
    "    model = TaxonomyExpander()\n",
    "    validator = TaxonomyValidator(model)\n",
    "    \n",
    "    # Run validation\n",
    "    validator.run_validation()\n",
    "    \n",
    "    # Calculate and print metrics\n",
    "    metrics = validator.print_metrics()\n",
    "    \n",
    "    # Save results to JSON\n",
    "    with open('validation_results.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'metrics': metrics,\n",
    "            'detailed_results': [\n",
    "                {\n",
    "                    'parent': r['parent'],\n",
    "                    'rank': r['rank'],\n",
    "                    'tp': r['tp'],\n",
    "                    'fp': r['fp'],\n",
    "                    'fn': r['fn'],\n",
    "                    'predicted_count': len(r['predicted']),\n",
    "                    'expected_count': len(r['expected'])\n",
    "                }\n",
    "                for r in validator.results\n",
    "            ]\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(\"\\nResults saved to validation_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
