{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd63b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fetching relationships for: English ---\n",
      "\n",
      "1. Querying Wikidata...\n",
      "Done.\n",
      "\n",
      "2. Parsing Wikipedia Infobox...\n",
      "wikicode\n",
      "English usually refers to:\n",
      "\n",
      "English language\n",
      "English people\n",
      "English may also refer to:\n",
      "\n",
      "Culture, language and peoples\n",
      "English, an adjective for something of, from, or related to England\n",
      "English, an Amish term for non-Amish, regardless of ethnicity\n",
      "English studies, the study of English language and literature\n",
      "\n",
      "Media\n",
      "English (2013 film), a Malayalam-language film\n",
      "English (novel), a Chinese book by Wang Gang\n",
      "English (2018 film), a Chinese adaptation\n",
      "The English (TV series), a 2022 Western-genre miniseries\n",
      "English (play), a 2022 play by Sanaz Toossi\n",
      "\n",
      "People and fictional characters\n",
      "English (surname), a list of people and fictional characters\n",
      "English Fisher (1928–2011), American boxing coach\n",
      "English Gardner (born 1992), American track and field sprinter\n",
      "English McConnell (1882–1928), Irish footballer\n",
      "Aiden English, a ring name of Matthew Rehwoldt (born 1987), American former professional wrestler\n",
      "Ben English, stage name of Derek Hay (born 1964), British porn actor\n",
      "\n",
      "Places in the United States\n",
      "English, Indiana\n",
      "English, Kentucky\n",
      "English, Brazoria County, Texas\n",
      "English, Red River County, Texas\n",
      "English, West Virginia\n",
      "\n",
      "Sport\n",
      "English (cue sports term), side spin on the cue ball\n",
      "\n",
      "See also\n",
      "Englisch, a surname\n",
      "Engrish\n",
      "All pages with titles beginning with English\n",
      "All pages with titles containing English\n",
      "Done.\n",
      "\n",
      "--- Combined Results ---\n",
      "{\n",
      "  \"language\": \"English\",\n",
      "  \"parents\": [\n",
      "    \"Anglic\"\n",
      "  ],\n",
      "  \"children\": [],\n",
      "  \"siblings\": [],\n",
      "  \"dialects\": [\n",
      "    \"England\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import mwparserfromhell\n",
    "import wikipediaapi\n",
    "import json\n",
    "\n",
    "def get_language_relationships_wikidata(language_name):\n",
    "    \"\"\"\n",
    "    Fetches language relationships from Wikidata using a SPARQL query.\n",
    "    \"\"\"\n",
    "    sparql_query = f\"\"\"\n",
    "    SELECT ?parentLabel ?childLabel ?dialectLabel ?siblingLabel\n",
    "    WHERE {{\n",
    "      ?language rdfs:label \"{language_name}\"@en .\n",
    "      ?language wdt:P31/wdt:P279* wd:Q34770 .\n",
    "\n",
    "      OPTIONAL {{ ?language wdt:P279 ?parent . }}\n",
    "      OPTIONAL {{ ?language wdt:P155 ?parent . }}\n",
    "      OPTIONAL {{ ?language wdt:P220 ?parent . }}\n",
    "      OPTIONAL {{ ?child wdt:P155 ?language . BIND(?language as ?parent) }}\n",
    "\n",
    "      OPTIONAL {{ ?child wdt:P155 ?language . }}\n",
    "\n",
    "      OPTIONAL {{ ?language wdt:P2341 ?dialect . }}\n",
    "      OPTIONAL {{ ?dialect wdt:P629 ?language . }}\n",
    "\n",
    "      OPTIONAL {{\n",
    "        ?language wdt:P155 ?commonParent .\n",
    "        ?sibling wdt:P155 ?commonParent .\n",
    "        FILTER(?sibling != ?language)\n",
    "      }}\n",
    "\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    try:\n",
    "        headers = {\n",
    "        'User-Agent': 'LanguageRelationshipFetcher/1.0 (your-name@example.com)'\n",
    "        }\n",
    "        response = requests.get(url, params={'query': sparql_query, 'format': 'json'}, headers=headers)\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error querying Wikidata: {e}\")\n",
    "        return {}\n",
    "\n",
    "    results = {\n",
    "        \"parents\": set(),\n",
    "        \"children\": set(),\n",
    "        \"dialects\": set(),\n",
    "        \"siblings\": set()\n",
    "    }\n",
    "\n",
    "    for item in data['results']['bindings']:\n",
    "        if 'parentLabel' in item:\n",
    "            results['parents'].add(item['parentLabel']['value'])\n",
    "        if 'childLabel' in item:\n",
    "            results['children'].add(item['childLabel']['value'])\n",
    "        if 'dialectLabel' in item:\n",
    "            results['dialects'].add(item['dialectLabel']['value'])\n",
    "        if 'siblingLabel' in item:\n",
    "            results['siblings'].add(item['siblingLabel']['value'])\n",
    "\n",
    "    for key in results:\n",
    "        results[key] = sorted(list(results[key]))\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_language_relationships_infobox(language_name):\n",
    "    \"\"\"\n",
    "    Fetches language relationships from the Wikipedia infobox.\n",
    "    \"\"\"\n",
    "    wiki_wiki = wikipediaapi.Wikipedia('LanguageTreeBuilder/1.0 (your-email@example.com)', 'en')\n",
    "    page = wiki_wiki.page(language_name)\n",
    "\n",
    "    if not page.exists():\n",
    "        print(f\"Page for '{language_name}' not found on Wikipedia.\")\n",
    "        return {}\n",
    "\n",
    "    wikicode = mwparserfromhell.parse(page.text)\n",
    "    print(\"wikicode\")\n",
    "    print(wikicode)\n",
    "    infoboxes = wikicode.filter_templates(matches=lambda t: t.name.strip().lower().startswith('infobox language'))\n",
    "\n",
    "    if not infoboxes:\n",
    "        return {}\n",
    "    infobox = infoboxes[0]\n",
    "\n",
    "    results = {\"parents\": set(), \"dialects\": set()}\n",
    "    parent_params = ['family', 'fam', 'family1', 'fam1', 'ancestor', 'ancestors']\n",
    "    dialect_params = ['dialects', 'varieties']\n",
    "\n",
    "    for param in infobox.params:\n",
    "        param_name = param.name.strip().lower()\n",
    "        param_value = param.value.strip_code().strip()\n",
    "\n",
    "        if any(p in param_name for p in parent_params):\n",
    "            parents = [p.strip() for p in param_value.replace('\\n', ',').split(',') if p.strip()]\n",
    "            results['parents'].update(parents)\n",
    "\n",
    "        if any(d in param_name for d in dialect_params):\n",
    "            dialects = [d.strip() for d in param_value.replace('\\n', ',').split(',') if d.strip()]\n",
    "            results['dialects'].update(dialects)\n",
    "\n",
    "    for key in results:\n",
    "        results[key] = sorted(list(results[key]))\n",
    "    return results\n",
    "\n",
    "def get_language_relationships(language_name):\n",
    "    \"\"\"\n",
    "    Main pipeline function to get language relationships.\n",
    "    \"\"\"\n",
    "    print(f\"--- Fetching relationships for: {language_name} ---\\n\")\n",
    "    print(\"1. Querying Wikidata...\")\n",
    "    wikidata_results = get_language_relationships_wikidata(language_name)\n",
    "    print(\"Done.\\n\")\n",
    "\n",
    "    print(\"2. Parsing Wikipedia Infobox...\")\n",
    "    infobox_results = get_language_relationships_infobox(language_name)\n",
    "    print(\"Done.\\n\")\n",
    "\n",
    "    combined_parents = set(wikidata_results.get(\"parents\", []))\n",
    "    if \"parents\" in infobox_results:\n",
    "        combined_parents.update(infobox_results[\"parents\"])\n",
    "\n",
    "    combined_dialects = set(wikidata_results.get(\"dialects\", []))\n",
    "    if \"dialects\" in infobox_results:\n",
    "        combined_dialects.update(infobox_results[\"dialects\"])\n",
    "\n",
    "    return {\n",
    "        \"language\": language_name,\n",
    "        \"parents\": sorted(list(combined_parents)),\n",
    "        \"children\": wikidata_results.get(\"children\", []),\n",
    "        \"siblings\": wikidata_results.get(\"siblings\", []),\n",
    "        \"dialects\": sorted(list(combined_dialects)),\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    language_to_check = \"English\"\n",
    "    relationships_data = get_language_relationships(language_to_check)\n",
    "    print(\"--- Combined Results ---\")\n",
    "    print(json.dumps(relationships_data, indent=2))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc995f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c3d5288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: English\n",
      "Dialect relationships found (count = 8):\n",
      "('British English', 'dialect_of', 'English')\n",
      "('North American English', 'dialect_of', 'English')\n",
      "('Caribbean English', 'dialect_of', 'English')\n",
      "('Australian English', 'dialect_of', 'English')\n",
      "('New Zealand English', 'dialect_of', 'English')\n",
      "('South African English', 'dialect_of', 'English')\n",
      "('Hiberno-English', 'dialect_of', 'English')\n",
      "('List of dialects of English', 'dialect_of', 'English')\n"
     ]
    }
   ],
   "source": [
    "# Dialect-only extractor using Wikipedia Infoboxes\n",
    "import re\n",
    "import requests\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "WIKI_API = \"https://en.wikipedia.org/w/api.php\"\n",
    "HEADERS = {\"User-Agent\": \"LanguageTreeNotebook/1.0 (educational)\"}\n",
    "\n",
    "def _get_page_content(title: str) -> str:\n",
    "    \"\"\"Fetch raw wikitext content of the given page title.\"\"\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvprop\": \"content\",\n",
    "        \"rvslots\": \"main\",\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(WIKI_API, params=params, headers=HEADERS, timeout=15)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "        if not pages:\n",
    "            return \"\"\n",
    "        page = next(iter(pages.values()))\n",
    "        revs = page.get(\"revisions\")\n",
    "        if not revs:\n",
    "            return \"\"\n",
    "        return revs[0].get(\"slots\", {}).get(\"main\", {}).get(\"*\", \"\")\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def _find_wiki_links(text: str) -> List[str]:\n",
    "    \"\"\"Return list of linked page titles from wiki link markup [[Title|...]].\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    links = []\n",
    "    for m in re.finditer(r\"\\[\\[([^|#\\]]+)(?:\\|[^\\]]*)?\\]\\]\", text):\n",
    "        t = m.group(1).strip()\n",
    "        if t:\n",
    "            links.append(t)\n",
    "    return links\n",
    "\n",
    "\n",
    "def _extract_infobox(wikitext: str) -> Dict[str, str]:\n",
    "    \"\"\"Extract raw key->value pairs from the Infobox (language or language family).\"\"\"\n",
    "    if not wikitext:\n",
    "        return {}\n",
    "\n",
    "    start = wikitext.find(\"{{Infobox language\")\n",
    "    if start == -1:\n",
    "        start = wikitext.find(\"{{Infobox language family\")\n",
    "    if start == -1:\n",
    "        m = re.search(r\"\\{\\{infobox\\s+(language|language family)\", wikitext, re.IGNORECASE)\n",
    "        if m:\n",
    "            start = m.start()\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    # Find the matching closing braces for the infobox\n",
    "    pos = start + 2\n",
    "    depth = 1\n",
    "    end = -1\n",
    "    while pos < len(wikitext):\n",
    "        if wikitext[pos:pos+2] == \"{{\":\n",
    "            depth += 1\n",
    "            pos += 2\n",
    "        elif wikitext[pos:pos+2] == \"}}\":\n",
    "            depth -= 1\n",
    "            pos += 2\n",
    "            if depth == 0:\n",
    "                end = pos\n",
    "                break\n",
    "        else:\n",
    "            pos += 1\n",
    "    if end == -1:\n",
    "        return {}\n",
    "\n",
    "    content = wikitext[start:end]\n",
    "    raw: Dict[str, str] = {}\n",
    "    current_key = None\n",
    "    current_val_lines: List[str] = []\n",
    "\n",
    "    for line in content.split(\"\\n\"):\n",
    "        s = line.strip()\n",
    "        if s.lower().startswith(\"{{infobox language\"):\n",
    "            continue\n",
    "        if s.startswith(\"|\") and \"=\" in s:\n",
    "            if current_key is not None and current_val_lines:\n",
    "                raw[current_key] = \"\\n\".join(current_val_lines).strip()\n",
    "            key, val = s[1:].split(\"=\", 1)\n",
    "            current_key = key.strip()\n",
    "            current_val_lines = [val.strip()]\n",
    "        elif s.startswith(\"|\") and current_key is not None:\n",
    "            current_val_lines.append(s[1:].strip())\n",
    "        elif current_key is not None and not s.startswith(\"|\"):\n",
    "            current_val_lines.append(s)\n",
    "\n",
    "    if current_key is not None and current_val_lines:\n",
    "        raw[current_key] = \"\\n\".join(current_val_lines).strip()\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def get_dialect_relationships(language_name: str) -> List[Tuple[str, str, str]]:\n",
    "    \"\"\"\n",
    "    Return only (dialect, 'dialect_of', language_name) tuples extracted from the\n",
    "    language's Wikipedia infobox. Looks at 'dialects' and 'dia1'..'dia40' fields.\n",
    "    \"\"\"\n",
    "    if not language_name or not isinstance(language_name, str):\n",
    "        return []\n",
    "\n",
    "    # Try a few common page title variations\n",
    "    candidates = [\n",
    "        f\"{language_name} language\",\n",
    "        language_name,\n",
    "        f\"{language_name} Language\",\n",
    "        f\"{language_name} languages\",\n",
    "        f\"{language_name} language family\",\n",
    "    ]\n",
    "\n",
    "    wikitext = \"\"\n",
    "    for t in candidates:\n",
    "        wikitext = _get_page_content(t)\n",
    "        if wikitext and (\"{{Infobox language\" in wikitext or \"{{Infobox language family\" in wikitext):\n",
    "            break\n",
    "    if not wikitext:\n",
    "        return []\n",
    "\n",
    "    infobox_raw = _extract_infobox(wikitext)\n",
    "    if not infobox_raw:\n",
    "        return []\n",
    "\n",
    "    found: List[str] = []\n",
    "\n",
    "    # Collect from explicit 'dialects' field if it contains links\n",
    "    if \"dialects\" in infobox_raw:\n",
    "        found.extend(_find_wiki_links(infobox_raw[\"dialects\"]))\n",
    "\n",
    "    # Collect from dia1..dia40 fields\n",
    "    for i in range(1, 41):\n",
    "        k = f\"dia{i}\"\n",
    "        if k in infobox_raw:\n",
    "            found.extend(_find_wiki_links(infobox_raw[k]))\n",
    "\n",
    "    # Deduplicate while preserving order\n",
    "    seen = set()\n",
    "    dialects: List[str] = []\n",
    "    for d in found:\n",
    "        if d not in seen:\n",
    "            seen.add(d)\n",
    "            dialects.append(d)\n",
    "\n",
    "    return [(d, \"dialect_of\", language_name) for d in dialects]\n",
    "\n",
    "\n",
    "# Demo usage in the notebook\n",
    "try:\n",
    "    lang = language_to_check  # If you've set this earlier in the notebook\n",
    "except NameError:\n",
    "    lang = \"English\"  # fallback demo language\n",
    "\n",
    "_dialects = get_dialect_relationships(lang)\n",
    "\n",
    "# Make a handy dict form too (useful for frontends)\n",
    "relationships_data = [\n",
    "    {\"entity1\": d, \"relationship\": \"dialect_of\", \"entity2\": lang}\n",
    "    for (d, _, lang) in _dialects\n",
    "]\n",
    "\n",
    "print(f\"Language: {lang}\")\n",
    "print(\"Dialect relationships found (count = {}):\".format(len(_dialects)))\n",
    "for rel in _dialects:\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd12a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
